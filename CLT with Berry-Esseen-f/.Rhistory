library(tidyverse)
library(knitr)
#Constructing the list in several steps
plot_theoretical_distributions <- function() {
#1. Define the distribution parameters
params <- list(
uniform = list(min = 0, max = 10),
exponential = list(rate = 0.5),
gamma = list(shape = 2, scale = 2)
)
# This part of the code may be modified with the insertion of new parameters (min, max, rate, shape and scale) determining the parent distributions
#2. Create a grid of x-values for each distribution
curve_data <- crossing(
distribution = factor(c("Uniform", "Exponential", "Gamma"), levels = c("Uniform", "Exponential", "Gamma")),
x = seq(-5, 25, length.out = 600) # Use many points for a smooth curve
) %>%
#3. Calculate the y-values for both PDF and CDF based on the distribution
mutate(
pdf_y = case_when(
distribution == "Uniform"     ~ dunif(x, min = params$uniform$min, max = params$uniform$max),
distribution == "Exponential" ~ dexp(x, rate = params$exponential$rate),
distribution == "Gamma"       ~ dgamma(x, shape = params$gamma$shape, scale = params$gamma$scale),
TRUE ~ NA_real_ # Default case
),
cdf_y = case_when(
distribution == "Uniform"     ~ punif(x, min = params$uniform$min, max = params$uniform$max),
distribution == "Exponential" ~ pexp(x, rate = params$exponential$rate),
distribution == "Gamma"       ~ pgamma(x, shape = params$gamma$shape, scale = params$gamma$scale),
TRUE ~ NA_real_
)
)
#4. Create the PDF plots using geom_line
p_pdf <- ggplot(curve_data, aes(x = x, y = pdf_y)) +
geom_line(color = "red", linewidth = 1.2) +
facet_wrap(~ distribution, scales = "free") +
labs(
title = "Probability Density Functions (PDFs)",
subtitle = "Illustrating the Shape of Parent Populations",
x = "Value",
y = "Density"
) +
theme_minimal() +
theme(plot.title = element_text(hjust = 0.5), plot.subtitle = element_text(hjust = 0.5))
#4. Create the CDF plots using geom_line
p_cdf <- ggplot(curve_data, aes(x = x, y = cdf_y)) +
geom_line(color = "dodgerblue", linewidth = 1.2) +
facet_wrap(~ distribution, scales = "free") +
labs(
title = "Cumulative Distribution Functions (CDFs)",
subtitle = "Illustrating the Shape of Parent Populations",
x = "Value",
y = "Cumulative Probability"
) +
theme_minimal() +
theme(plot.title = element_text(hjust = 0.5), plot.subtitle = element_text(hjust = 0.5))
#5. Return both plot objects in a list
return(list(
pdf_plots = p_pdf,
cdf_plots = p_cdf
))
}
#6. Create the list
theoretical_plots <- plot_theoretical_distributions()
theoretical_plots$cdf_plots
theoretical_plots$pdf_plots
plot_clt_final_version <- function(population_size = 10000, sample_size = 50, num_samples = 10000) {
set.seed(42) # for reproducibility
#1. Create populations and store true parameters
population_uniform <- runif(population_size, 0, 10)
population_exponential <- rexp(population_size, rate = 0.5)
population_gamma <- rgamma(population_size, shape = 2, scale = 2)
pop_stats <- data.frame(
distribution = factor(c("Uniform", "Exponential", "Gamma"), levels = c("Uniform", "Exponential", "Gamma")),
pop_mean = c(mean(population_uniform), mean(population_exponential), mean(population_gamma)),
pop_sd = c(sd(population_uniform), sd(population_exponential), sd(population_gamma))
)
#2. Simulate sample means
simulate_means <- function(population, n_samples, samp_size) {
replicate(n_samples, mean(sample(population, size = samp_size, replace = TRUE)))
}
plot_data <- data.frame(
means = c(
simulate_means(population_uniform, num_samples, sample_size),
simulate_means(population_exponential, num_samples, sample_size),
simulate_means(population_gamma, num_samples, sample_size)
),
distribution = factor(rep(c("Uniform", "Exponential", "Gamma"), each = num_samples), levels = c("Uniform", "Exponential", "Gamma"))
)
#3. Create data for annotations and vertical lines
stats_summary <- plot_data %>%
group_by(distribution) %>%
summarise(
obs_mean = mean(means),
obs_var = var(means),
.groups = 'drop'
) %>%
left_join(pop_stats, by = "distribution") %>%
mutate(
obs_sd = sqrt(obs_var),
theoretical_sd = pop_sd / sqrt(sample_size),
peak_y = dnorm(pop_mean, mean = pop_mean, sd = theoretical_sd),
segment_y_end = peak_y / 3,
label = sprintf(
"Observed SD: %.4f\nTheoretical SD (σ/√n): %.4f",
obs_sd, theoretical_sd
)
)
#4. Create data for the theoretical red durve
curve_data <- plot_data %>%
group_by(distribution) %>%
reframe(x_coords = seq(min(means), max(means), length.out = 200)) %>%
left_join(pop_stats, by = "distribution") %>%
mutate(
y_coords = dnorm(x_coords, mean = pop_mean, sd = pop_sd / sqrt(sample_size))
)
#5. Generate the final plot
p <- ggplot(plot_data, aes(x = means)) +
geom_histogram(aes(y = after_stat(density)), bins = 40, fill = "lightblue", color = "black", alpha = 0.7) +
geom_line(data = curve_data, aes(x = x_coords, y = y_coords), color = "red", linewidth = 1) +
#6. Include the vertical line segments for spread
geom_segment(data = stats_summary, aes(x = pop_mean, y = 0, xend = pop_mean, yend = segment_y_end, color = "Theoretical"), linetype = "solid", linewidth = 1) +
geom_segment(data = stats_summary, aes(x = pop_mean - theoretical_sd, y = 0, xend = pop_mean - theoretical_sd, yend = segment_y_end, color = "Theoretical"), linetype = "dashed", linewidth = 1) +
geom_segment(data = stats_summary, aes(x = pop_mean + theoretical_sd, y = 0, xend = pop_mean + theoretical_sd, yend = segment_y_end, color = "Theoretical"), linetype = "dashed", linewidth = 1) +
geom_segment(data = stats_summary, aes(x = obs_mean, y = 0, xend = obs_mean, yend = segment_y_end, color = "Observed"), linetype = "solid", linewidth = 1) +
geom_segment(data = stats_summary, aes(x = obs_mean - obs_sd, y = 0, xend = obs_mean - obs_sd, yend = segment_y_end, color = "Observed"), linetype = "dashed", linewidth = 1) +
geom_segment(data = stats_summary, aes(x = obs_mean + obs_sd, y = 0, xend = obs_mean + obs_sd, yend = segment_y_end, color = "Observed"), linetype = "dashed", linewidth = 1) +
geom_text(data = stats_summary, aes(label = label), x = Inf, y = Inf, hjust = 1.05, vjust = 1.05, size = 3.5) +
facet_wrap(~ distribution, scales = "free") +
scale_color_manual(name = "Spread (SD) Indicators", values = c("Theoretical" = "darkgreen", "Observed" = "darkorange")) +
labs(
title = "Distribution of Sample Means vs. Theoretical Normal Curve (CLT)",
subtitle = paste("Solid lines are Means, Dashed lines are plus-minus one Std. Dev. | n =", sample_size),
x = "Sample Mean",
y = "Density"
) +
theme_minimal() +
theme(
plot.title = element_text(hjust = 0.5, size = 16),
plot.subtitle = element_text(hjust = 0.5, size = 12),
legend.position = "bottom"
)
return(p)
}
plot_clt_final_version(sample_size = 5)
plot_clt_final_version(sample_size = 50)
plot_clt_final_version(sample_size = 100)
plot_clt_final_version(sample_size = 200)
plot_clt_cdf_convergence <- function(population_size = 10000, sample_size = 50, num_samples = 10000) {
set.seed(42) # for reproducibility
# 1. Create populations and store true parameters
population_uniform <- runif(population_size, 0, 10)
population_exponential <- rexp(population_size, rate = 0.5)
population_gamma <- rgamma(population_size, shape = 2, scale = 2)
pop_stats <- data.frame(
distribution = factor(c("Uniform", "Exponential", "Gamma"), levels = c("Uniform", "Exponential", "Gamma")),
pop_mean = c(mean(population_uniform), mean(population_exponential), mean(population_gamma)),
pop_sd = c(sd(population_uniform), sd(population_exponential), sd(population_gamma))
)
# 2. Simulate sample means
simulate_means <- function(population, n_samples, samp_size) {
replicate(n_samples, mean(sample(population, size = samp_size, replace = TRUE)))
}
plot_data <- data.frame(
means = c(
simulate_means(population_uniform, num_samples, sample_size),
simulate_means(population_exponential, num_samples, sample_size),
simulate_means(population_gamma, num_samples, sample_size)
),
distribution = factor(rep(c("Uniform", "Exponential", "Gamma"), each = num_samples), levels = c("Uniform", "Exponential", "Gamma"))
)
# 3. Pre-calculate data for the theoretical normal CDF curve
# This is the robust method to ensure the correct curve is drawn in each facet.
theoretical_cdf_data <- plot_data %>%
group_by(distribution) %>%
reframe(x_coords = seq(min(means), max(means), length.out = 500)) %>%
left_join(pop_stats, by = "distribution") %>%
mutate(
y_coords = pnorm(x_coords, mean = pop_mean, sd = pop_sd / sqrt(sample_size))
)
# 4. Generate the plot
p <- ggplot(plot_data, aes(x = means)) +
# Plot the empirical CDF from the simulated data (the "real" result)
stat_ecdf(aes(color = "Empirical CDF"), geom = "step", linewidth = 1) +
# Plot the theoretical normal CDF (the CLT's prediction)
geom_line(
data = theoretical_cdf_data,
aes(x = x_coords, y = y_coords, color = "Theoretical Normal CDF"),
linewidth = 1.2,
linetype = "dashed"
) +
facet_wrap(~ distribution, scales = "free_x") +
# 5. Control appearance and add legend
scale_color_manual(
name = "Distribution Type",
values = c("Empirical CDF" = "dodgerblue", "Theoretical Normal CDF" = "red")
) +
labs(
title = "CLT Convergence of Cumulative Distribution Functions (CDFs)",
subtitle = paste("Comparing simulated ECDF to the theoretical Normal CDF for n =", sample_size),
x = "Sample Mean",
y = "Cumulative Probability"
) +
theme_minimal() +
theme(
plot.title = element_text(hjust = 0.5, size = 16),
plot.subtitle = element_text(hjust = 0.5, size = 12),
legend.position = "bottom"
)
return(p)
}
plot_clt_cdf_convergence(sample_size = 5)
plot_clt_cdf_convergence(sample_size = 200)
simulate_berry_esseen_snapshots <- function(
distributions_to_test = c("Uniform", "Exponential"),
n_values = c(5, 10, 20, 50, 100, 200, 500),
num_simulations = 10000,
n_values_for_x_plot = c(20, 100, 200) # Updated argument
) {
#1. Parameter setup and moment calculation
set.seed(42)
params <- list(Uniform = list(min = 0, max = 10), Exponential = list(rate = 0.5))
C_BE <- 0.4748
message("Displaying exact theoretical moments (just for the record...)")
moment_calculations <- lapply(distributions_to_test, function(dist) {
if (dist == "Uniform") {
a <- params$Uniform$min; b <- params$Uniform$max; mu <- (a + b) / 2; sigma <- (b - a) / sqrt(12)
rho_integrand <- function(x) abs(x - mu)^3 * dunif(x, a, b); rho <- integrate(rho_integrand, lower = a, upper = b)$value
} else if (dist == "Exponential") {
lambda <- params$Exponential$rate; mu <- 1 / lambda; sigma <- 1 / lambda
rho_integrand <- function(x) abs(x - mu)^3 * dexp(x, rate = lambda); rho <- integrate(rho_integrand, lower = 0, upper = Inf)$value
}
data.frame(distribution = dist, mu = mu, sigma = sigma, rho = rho, shape_factor = rho / (sigma^3))
})
pop_moments <- bind_rows(moment_calculations)
print(pop_moments)
#2. Simulation and generation of Plot 1
simulation_grid <- crossing(distribution = distributions_to_test, n = n_values)
results_list <- pmap(simulation_grid, function(distribution, n) {
moments <- pop_moments %>% filter(distribution == !!distribution)
z_values <- replicate(num_simulations, {
sample_data <- switch(distribution, "Uniform" = runif(n, params$Uniform$min, params$Uniform$max), "Exponential" = rexp(n, rate = params$Exponential$rate))
(mean(sample_data) - moments$mu) / (moments$sigma / sqrt(n))
})
ecdf_z <- ecdf(z_values); knots_z <- knots(ecdf_z); observed_error <- max(abs(ecdf_z(knots_z) - pnorm(knots_z)))
theoretical_bound <- C_BE * moments$shape_factor * (1 / sqrt(n))
data.frame(distribution = distribution, n = n, observed_error = observed_error, theoretical_bound = theoretical_bound)
})
results_df <- bind_rows(results_list)
plot1_data <- results_df %>% pivot_longer(c("observed_error", "theoretical_bound"), names_to = "type", values_to = "error_value")
p_error_vs_n <- ggplot(plot1_data, aes(x = n, y = error_value, color = type, shape = type)) + geom_line(aes(linetype = type), linewidth = 1) + geom_point(size = 3) +
facet_wrap(~ distribution, scales = "free_y") + scale_y_log10() + scale_color_manual(values = c(observed_error = "blue", theoretical_bound = "red"), labels = c("Observed Max Error", "Theoretical Bound")) +
scale_shape_manual(values = c(observed_error = 16, theoretical_bound = 17), labels = c("Observed Max Error", "Theoretical Bound")) +
scale_linetype_manual(values = c(observed_error = "solid", theoretical_bound = "dashed"), labels = c("Observed Max Error", "Theoretical Bound")) +
labs(title = "Berry-Esseen Theorem: Observed Error vs. Theoretical Bound", subtitle = "Note: y-axis is on a log scale to show the convergence rate.", x = "Sample Size (n)", y = "Maximum Error |F_n(x) - Φ(x)| (log scale)") +
theme_minimal() + theme(legend.title = element_blank(), legend.position = "bottom")
#3. Simulation for plot 2
# A grid for all snapshot simulations
snapshot_grid <- crossing(distribution = distributions_to_test, n = n_values_for_x_plot)
error_curve_list <- pmap(snapshot_grid, function(distribution, n) {
moments <- pop_moments %>% filter(distribution == !!distribution)
z_values_fixed_n <- replicate(num_simulations, {
sample_data <- switch(distribution, "Uniform" = runif(n, params$Uniform$min, params$Uniform$max), "Exponential" = rexp(n, rate = params$Exponential$rate))
(mean(sample_data) - moments$mu) / (moments$sigma / sqrt(n))
})
ecdf_z <- ecdf(z_values_fixed_n)
x_grid <- seq(min(z_values_fixed_n), max(z_values_fixed_n), length.out = 1000)
# Return a data frame that includes the 'n' for this simulation run
data.frame(distribution = distribution, n = n, x = x_grid, error_term = ecdf_z(x_grid) - pnorm(x_grid))
})
error_curve_df <- bind_rows(error_curve_list)
# 4. Generate Plot 2 using facet_grid
p_error_vs_x <- ggplot(error_curve_df, aes(x = x, y = error_term)) +
geom_line(color = "purple", linewidth = 1) +
geom_hline(yintercept = 0, linetype = "dashed", color = "black") +
# Use facet_grid to create a matrix of plots: rows are distributions, columns are n
facet_grid(distribution ~ n, labeller = label_both, scales = "free_x") +
labs(
title = "Snapshots of the Berry-Esseen Error Term F_n(x) - Φ(x)",
subtitle = "Showing convergence to zero as sample size (n) increases",
x = "Standardized Value (x)",
y = "Error Term"
) +
theme_minimal() +
theme(strip.text = element_text(size = 10)) # Adjust facet label size if needed
#5. Return Plots
#message("\nDone.")
return(list(error_vs_n_plot = p_error_vs_n, error_vs_x_plot = p_error_vs_x))
}
be_plots_snapshots <- simulate_berry_esseen_snapshots()
be_plots_snapshots$error_vs_n_plot
