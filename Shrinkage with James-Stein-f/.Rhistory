library(tidyverse)
library(tidyverse)
baseball_data <- read.csv("baseball.csv")
library(tidyverse)
baseball_data <- read.csv("baseball.csv")
baseball_data
baseball_data_n <- baseball_data %>%
mutate(Observed_Avg = Hits / At_Bats)
baseball_data_n
# This calculate the MSE for the sample mean
sse_mle_prel <- sum((baseball_data_n$Observed_Avg - baseball_data_n$True_Avg)^2)
print(sse_mle_prel)
# This is just the observed average above
mle_estimates <- baseball_data_n$Observed_Avg
# James-Stein Estimation
# Defining the number of parameters and prescribing the variance
p <- nrow(baseball_data_n)
sigma_sq <- 0.0055 # Variance assumed as known (for simplicity)
# Calculating the shrinkage factor, say  C
sum_sq_dev <- sum((baseball_data_n$Observed_Avg)^2)
C <- 1 - ((p - 2) * sigma_sq) / sum_sq_dev
# Calculating the JS estimates
js_estimates <- C * (baseball_data_n$Observed_Avg)
results <- baseball_data_n %>%
mutate(MLE_Estimate = mle_estimates,
JS_Estimate = js_estimates)
print(results)
# Calculating SSE for each estimator
sse_mle <- sum((results$MLE_Estimate - results$True_Avg)^2)
sse_js <- sum((results$JS_Estimate - results$True_Avg)^2)
# Computing the "improvement rate" of JS w.r.t. MLE
improv_js_mle <- round(100 * (1 - sse_js/sse_mle), 1)
performance <- tibble(
Estimator = c("MLE", "James-Stein (origin)", "Improvement (%)"),
SSE = c(sse_mle, sse_js, improv_js_mle)
)
# Print the performance table
knitr::kable(performance, digits = 4,
caption = "SSE Comparison for JS (origin) vs MLE")
# Here we compute the "grand mean" of the observed mean (for further use)
y_gm <- mean(baseball_data_n$Observed_Avg)
# Here we implement the "ggplot" code
results %>%
arrange(desc(Observed_Avg)) %>%
mutate(Player = fct_inorder(Player)) %>%
ggplot(aes(x = Player)) +
geom_point(aes(y = MLE_Estimate, color = "MLE (Observed)"), size = 3) +
geom_point(aes(y = JS_Estimate, color = "James-Stein"), size = 3) +
geom_point(aes(y = True_Avg, color = "True Career Avg"), size = 3, shape = 3, stroke = 1.5) +
geom_hline(aes(yintercept = y_gm, linetype = "Grand Mean"), color = "gray50") +
geom_segment(aes(xend = Player, y = MLE_Estimate, yend = JS_Estimate),
arrow = arrow(length = unit(0.2, "cm")), color = "blue") +
scale_color_manual(name = "Estimate Type",
values = c("MLE (Observed)" = "darkred",
"James-Stein" = "blue",
"True Career Avg" = "darkgreen")) +
scale_linetype_manual(name = "", values = c("Grand Mean" = "dashed")) +
labs(title = "JS Shrinkage (toward the origin): Baseball Batting Averages",
y = "Batting Average", x = "Player") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
# James-Stein Estimation (toward the grande mean and with the same population parameters as peviously)
# Calculating the shrinkage factor, say C_shr
sum_sq_dev_shr <- sum((baseball_data_n$Observed_Avg - y_gm)^2)
C_shr <- 1 - ((p - 3) * sigma_sq) / sum_sq_dev_shr
# Calculating  the new JS estimates
js_estimates_shr <- y_gm + C_shr * (baseball_data_n$Observed_Avg - y_gm)
# Combine into a results tibble
results_shr <- baseball_data_n %>%
mutate(MLE_Estimate = mle_estimates,
JS_Estimate_shr = js_estimates_shr,y_gm)
# Preparing for display (hiding two columns for better visualization)
results_shr_display <- results_shr %>%
select(Player, True_Avg:JS_Estimate_shr,y_gm)
#
print(results_shr_display)
# Calculating the performance of the new SSE estimator
sse_js_shr <- sum((results_shr$JS_Estimate_shr - results$True_Avg)^2)
improv_js_mle_shr <- round(100 * (1 - sse_js_shr/sse_mle), 1)
performance_shr <- tibble(
Estimator = c("MLE", "James-Stein (grand mean)", "Improvement (%)"),
SSE = c(sse_mle, sse_js_shr, improv_js_mle_shr)
)
# Print the performance table
knitr::kable(performance_shr, digits = 4,
caption = "SSE Comparison for JS (grand mean) vs MLE")
results_shr %>%
arrange(desc(Observed_Avg)) %>%
mutate(Player = fct_inorder(Player)) %>%
ggplot(aes(x = Player)) +
geom_point(aes(y = MLE_Estimate, color = "MLE (Observed)"), size = 3) +
geom_point(aes(y = JS_Estimate_shr, color = "James-Stein"), size = 3) +
geom_point(aes(y = True_Avg, color = "True Career Avg"), size = 3, shape = 3, stroke = 1.5) +
geom_hline(aes(yintercept = y_gm, linetype = "Grand Mean"), color = "gray50") +
geom_segment(aes(xend = Player, y = MLE_Estimate, yend = JS_Estimate_shr),
arrow = arrow(length = unit(0.2, "cm")), color = "blue") +
scale_color_manual(name = "Estimate Type",
values = c("MLE (Observed)" = "darkred",
"James-Stein" = "blue",
"True Career Avg" = "darkgreen")) +
scale_linetype_manual(name = "", values = c("Grand Mean" = "dashed")) +
labs(title = "James-Stein Shrinkage (Grand Mean): Baseball Batting Averages",
y = "Batting Average", x = "Player") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
run_js_simulation <- function(p , n , sigma_sq_true , mu_true ) {
# --- 1. Generate the Data ---
# Create a matrix of n observations for each of the p parameters.
# Each column i is drawn from N(mu_true[i], sigma_sq_true).
data_matrix <- matrix(rnorm(n * p, mean = mu_true, sd = sqrt(sigma_sq_true)),
nrow = n, ncol = p, byrow = TRUE)
# --- 2. Calculating the MLE, which is the sample mean for each column (averagin over the observations).
mle_estimates_normal <- colMeans(data_matrix)
# Redefining the variance, which we assume as known (for simplicity)
S_sq <- sigma_sq_true
# James-Stein (JS) Estimator (origin as a target)
# Calculating the shrinkage factor.
y_bar_norm_sq <- sum(mle_estimates_normal^2)
shrinkage_factor <- (((p - 2) * S_sq)/n) / y_bar_norm_sq
# Calculating the JS estimator proper
C_or <- 1 - shrinkage_factor
js_estimates_normal <- C_or * mle_estimates_normal
# Evaluating the performance...
sse_mle_normal <- sum((mle_estimates_normal - mu_true)^2)
sse_js_normal <- sum((js_estimates_normal - mu_true)^2)
improv_js_normal <- round(100 * (1 - sse_js_normal/sse_mle_normal), 1)
#...and preparing the table
performance_normal <- tibble(
Estimator = c("MLE", "James-Stein", "Improvement (%)"),
SSE = c(sse_mle_normal, sse_js_normal, improv_js_normal)
)
# Preparing for plotting
plot_data <- tibble(
Parameter_Index = 1:p,
True_Mean = mu_true,
MLE_Estimate_normal = mle_estimates_normal,
JS_Estimate_normal = js_estimates_normal
)
# Generating the plot
plot_normal <- ggplot(plot_data, aes(x = factor(Parameter_Index))) +
geom_point(aes(y = MLE_Estimate_normal, color = "MLE (Sample Mean)"), size = 3) +
geom_point(aes(y = JS_Estimate_normal, color = "James-Stein"), size = 3) +
geom_point(aes(y = True_Mean, color = "True Mean"), size = 4, shape = 4, stroke = 1.5) +
geom_hline(aes(yintercept = 0, linetype = "Shrinkage Target"), color = "gray50") +
geom_segment(aes(xend = factor(Parameter_Index), y = MLE_Estimate_normal, yend = JS_Estimate_normal),
arrow = arrow(length = unit(0.2, "cm")), color = "blue") +
scale_color_manual(name = "Estimate Type",
values = c("MLE (Sample Mean)" = "darkred",
"James-Stein" = "blue",
"True Mean" = "darkgreen")) +
scale_linetype_manual(name = "", values = c("Shrinkage Target" = "dashed")) +
labs(title = paste("James-Stein Shrinkage with", p, "Multivariate Normal Means"),
subtitle = "Estimates are shrunk towards the origin",
y = "Value", x = "Parameter Index") +
theme_minimal() +
theme(legend.position = "bottom")
# The final result
return(list(performance = performance_normal, plot = plot_normal))
}
# Set seed for reproducibility
set.seed(235)
# Run the simulation
sim_or <- run_js_simulation(p = 18, n = 10, sigma_sq_true = 25, mu_true =  rnorm(18, mean = 10, sd = 2))
# Print the performance table
knitr::kable(sim_or$performance, digits = 4,
caption = "SSE Comparison for JS (origin) and MLE")
print(sim_or$plot)
# The function is renamed to indicate it shrinks to the Grand Mean
run_js_simulation_gm <- function(p , n , sigma_sq_true , mu_true ) {
# Generating the data
data_matrix <- matrix(rnorm(n * p, mean = mu_true, sd = sqrt(sigma_sq_true)),
nrow = n, ncol = p, byrow = TRUE)
# Calculating MLE (same as before)
mle_estimates_normal <- colMeans(data_matrix)
# Renaming the variance (same as before)
S_sq <- sigma_sq_true
# James-Stein, with the target being the "grand mean" of all the individual MLEs.
grand_mean <- mean(mle_estimates_normal)
sum_sq_dev_from_grand_mean <- sum((mle_estimates_normal - grand_mean)^2)
shrinkage_factor <- (((p - 3) * S_sq) / n) / sum_sq_dev_from_grand_mean
C_gm <- 1 - shrinkage_factor
js_estimates_gm <- grand_mean + C_gm * (mle_estimates_normal - grand_mean)
# Evaluating the performance
sse_mle_normal <- sum((mle_estimates_normal - mu_true)^2)
sse_js_normal_gm <- sum((js_estimates_gm - mu_true)^2)
improv_js_normal_gm <- round(100 * (1 - sse_js_normal_gm/sse_mle_normal), 1)
# Performance tibble
performance_gm <- tibble( # <-- CHANGED
Estimator = c("MLE", "James-Stein (Grand Mean)", "Improvement (%)"),
SSE = c(sse_mle_normal, sse_js_normal_gm, improv_js_normal_gm)
)
# Preparing for plotting
plot_data_gm <- tibble(
Parameter_Index = 1:p,
True_Mean = mu_true,
MLE_Estimate_normal = mle_estimates_normal,
JS_Estimate_gm = js_estimates_gm #
)
# Generating the plot
plot_gm <- ggplot(plot_data_gm, aes(x = factor(Parameter_Index))) + # <-- CHANGED (data source)
geom_point(aes(y = MLE_Estimate_normal, color = "MLE (Sample Mean)"), size = 3) +
geom_point(aes(y = JS_Estimate_gm, color = "James-Stein"), size = 3) + # <-- CHANGED (y-aesthetic)
geom_point(aes(y = True_Mean, color = "True Mean"), size = 4, shape = 4, stroke = 1.5) +
geom_hline(aes(yintercept = grand_mean, linetype = "Shrinkage Target (Grand Mean)"), color = "gray50") +
geom_segment(aes(xend = factor(Parameter_Index), y = MLE_Estimate_normal, yend = JS_Estimate_gm), # <-- CHANGED (yend)
arrow = arrow(length = unit(0.2, "cm")), color = "blue") +
scale_color_manual(name = "Estimate Type",
values = c("MLE (Sample Mean)" = "darkred",
"James-Stein" = "blue",
"True Mean" = "darkgreen")) +
scale_linetype_manual(name = "", values = c("Shrinkage Target (Grand Mean)" = "dashed")) +
labs(title = paste("James-Stein Shrinkage with", p, "Multivariate Normal Means"),
subtitle = paste("Estimates are shrunk towards the Grand Mean (", round(grand_mean, 2), ")"),
y = "Value", x = "Parameter Index") +
theme_minimal() +
theme(legend.position = "bottom")
# The final result
return(list(performance = performance_gm, plot = plot_gm, grand_mean = grand_mean))
}
